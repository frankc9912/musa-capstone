{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Uj22WqO6lgL"
   },
   "source": [
    "### Homework of GPU programming for the urban analysis\n",
    "\n",
    "Frank Chen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q78ninoELGCc"
   },
   "source": [
    "#### Step 1. Computer Set Up\n",
    "\n",
    "In this section, I will introduce how to set up the PC for the GPU programming, especially for the PyCUDA programming.\n",
    "\n",
    "First, you need to have a NVIDIA GPU card, and install the CUDA toolkit. You can download the [CUDA toolkit from the NVIDIA website](https://developer.nvidia.com/cuda-downloads) for your own operating system. As an example, I'm running the Windows 10 with an RTX 3070 graphic card, so I download and install the CUDA toolkit for Windows 10.\n",
    "\n",
    "Next, you need to install the Visual Studio, which is required by the CUDA toolkit for C++ programming. If you don't want to use the complete version of Visual Studio, you can install the [Visual Studio Build Tools](https://visualstudio.microsoft.com/zh-hans/downloads/?q=build+tools) instead, which is more lightweight and includes the necessary components for the CUDA programming. Remember to choose \"Desktop development with C++\" when you install it, and add the file path containing the cl.exe to the system environment variable. For file path, please refer to [this post on stackoverflow](https://stackoverflow.com/questions/8125826/error-compiling-cuda-from-command-prompt).\n",
    "\n",
    "Finally, you need to install the PyCUDA module, which is a Python wrapper for the CUDA programming. You can install it through conda or pip. I'm using mamba as the package manager, so I install the PyCUDA module by running the following command: `mamba install -c conda-forge pycuda`.\n",
    "\n",
    "To examine whether the PyCUDA module is installed successfully, you can run `nvcc --version` in the terminal to check the version of the CUDA toolkit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2. Process the Data\n",
    "\n",
    "In this section, I will introduce how to import the PyCUDA module and process the data for the GPU programming.\n",
    "\n",
    "First, we need to import all the modules we need for the GPU programming. Then, we need to load the data using `rasterio` and copy the metadata of the input raster to the output raster. We also need to define the kernel function for the GPU programming. We then get the time and sun parameters including azimuth and elevation from the [NOAA solar position calculator](https://gml.noaa.gov/grad/solcalc/azel.html). Finally, we write a for loop to calculate the shadow distribution for each hour and export the result to tif file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pycuda installed and ready to use.\n",
      "1 device(s) found.\n",
      "Device #0: NVIDIA GeForce RTX 3070\n",
      "<module 'pycuda.driver' from 'e:\\\\miniforge3\\\\envs\\\\spatial\\\\lib\\\\site-packages\\\\pycuda\\\\driver.py'>\n",
      "The DSM bounds are: BoundingBox(left=2712748.0, bottom=259294.0, right=2717948.0, top=264494.0)\n",
      "Cell size (width, height): (2.0, 2.0)\n",
      "Processing time: 8h, Azimuth: 93.7, Elevation: 32.87\n",
      "Saved shadow file for time 8h to data/shadow_8.tif\n",
      "Processing time: 9h, Azimuth: 104.85, Elevation: 44.2\n",
      "Saved shadow file for time 9h to data/shadow_9.tif\n",
      "Processing time: 10h, Azimuth: 119.64, Elevation: 54.83\n",
      "Saved shadow file for time 10h to data/shadow_10.tif\n",
      "Processing time: 11h, Azimuth: 141.98, Elevation: 63.58\n",
      "Saved shadow file for time 11h to data/shadow_11.tif\n",
      "Processing time: 12h, Azimuth: 175.62, Elevation: 67.82\n",
      "Saved shadow file for time 12h to data/shadow_12.tif\n",
      "Processing time: 13h, Azimuth: 211.21, Elevation: 65.07\n",
      "Saved shadow file for time 13h to data/shadow_13.tif\n",
      "Processing time: 14h, Azimuth: 236, Elevation: 57.06\n",
      "Saved shadow file for time 14h to data/shadow_14.tif\n",
      "Processing time: 15h, Azimuth: 252.08, Elevation: 46.7\n",
      "Saved shadow file for time 15h to data/shadow_15.tif\n",
      "Processing time: 16h, Azimuth: 263.83, Elevation: 35.47\n",
      "Saved shadow file for time 16h to data/shadow_16.tif\n",
      "Processing time: 17h, Azimuth: 273.63, Elevation: 23.99\n",
      "Saved shadow file for time 17h to data/shadow_17.tif\n",
      "Processing time: 18h, Azimuth: 282.74, Elevation: 12.65\n",
      "Saved shadow file for time 18h to data/shadow_18.tif\n"
     ]
    }
   ],
   "source": [
    "from pycuda.compiler import SourceModule\n",
    "import pycuda\n",
    "from pycuda import gpuarray\n",
    "from pycuda import compiler\n",
    "import pycuda.autoinit             # PyCuda autoinit\n",
    "import pycuda.driver as cuda       # PyCuda In, Out helpers\n",
    "import os, os.path\n",
    "import rasterio as rio\n",
    "from osgeo import gdal\n",
    "from osgeo.gdalconst import *\n",
    "import numpy as np\n",
    "import rasterio\n",
    "import time\n",
    "import math\n",
    "# Load the Drive helper and mount\n",
    "# from google.colab import drive\n",
    "import matplotlib.cm as colormap   # Library to plot\n",
    "import numpy                       # Fast math library\n",
    "import matplotlib.image as mpimg       # reading images to numpy arrays\n",
    "import matplotlib.pyplot as plt        # to plot any graph\n",
    "import scipy.ndimage as ndi            # to determine shape centrality\n",
    "# matplotlib setup\n",
    "\n",
    "%matplotlib inline\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = (8, 8)      # setting default size of plots\n",
    "\n",
    "print(\"pycuda installed and ready to use.\")\n",
    "\n",
    "print(\"%d device(s) found.\" % cuda.Device.count())\n",
    "for ordinal in range(cuda.Device.count()):\n",
    "    dev = cuda.Device(ordinal)\n",
    "    print (\"Device #%d: %s\" % (ordinal, dev.name()))\n",
    "print (cuda)\n",
    "\n",
    "dsm_file = \"data/row11-col17.tif\"\n",
    "\n",
    "with rio.open(dsm_file) as dsm_dataset:\n",
    "        # Read bounds and image data\n",
    "        dsm_bounds = dsm_dataset.bounds\n",
    "        dsm_img = dsm_dataset.read(1)\n",
    "        print('The DSM bounds are:', dsm_bounds)\n",
    "\n",
    "        # Get the affine transformation parameters\n",
    "        transform = dsm_dataset.transform\n",
    "        # Pixel sizes (cell sizes)\n",
    "        pixel_width = transform[0]           # x-direction scale\n",
    "        pixel_height = -transform[4]         # y-direction scale (usually negative)\n",
    "        cell_size = (pixel_width, pixel_height)\n",
    "        print('Cell size (width, height):', cell_size)\n",
    "\n",
    "        # Copy metadata for later export\n",
    "        metadata = dsm_dataset.meta.copy()\n",
    "\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "from pycuda.compiler import SourceModule\n",
    "\n",
    "# Define the CUDA kernel for the shadow calculation\n",
    "kernel_shadow = \"\"\"\n",
    "#define PI 3.1415926\n",
    "\n",
    "__global__ void calculate_shadow(float *dsm, bool *shadow, int width, int height, float cell_size, float sun_azimuth, float sun_elevation) {\n",
    "    int x = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int y = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "    // Check if the thread is within the bounds of the image\n",
    "    if (x >= width || y >= height)\n",
    "        return;\n",
    "\n",
    "    int idx = y * width + x;\n",
    "\n",
    "    // Convert sun azimuth and elevation to radians\n",
    "    float azimuth_rad = sun_azimuth * 3.14159 / 180.0;\n",
    "    float elevation_rad = sun_elevation * 3.14159 / 180.0;\n",
    "\n",
    "    // Direction of the shadow ray based on sun azimuth\n",
    "    float dx = sin(azimuth_rad);\n",
    "    float dy = -cos(azimuth_rad);\n",
    "    float dz = tan(elevation_rad);\n",
    "\n",
    "    // Initial height at the current pixel\n",
    "    float initial_height = dsm[idx];\n",
    "    bool in_shadow = false;\n",
    "\n",
    "    // Trace the shadow ray\n",
    "    for (float t = cell_size; t < 2000.0f; t += cell_size) { // Limit tracing distance\n",
    "        int x_offset = x + int(dx * t / cell_size);\n",
    "        int y_offset = y + int(dy * t / cell_size);\n",
    "\n",
    "        if (x_offset < 0 || x_offset >= width || y_offset < 0 || y_offset >= height)\n",
    "            break;  // Out of bounds\n",
    "\n",
    "        int offset_idx = y_offset * width + x_offset;\n",
    "\n",
    "        // Calculate height along the ray\n",
    "        float height_along_ray = initial_height + dz * t;\n",
    "\n",
    "        // Check if there is a higher point along the path\n",
    "        if (dsm[offset_idx] > height_along_ray) {\n",
    "            in_shadow = true;\n",
    "            break;\n",
    "        }\n",
    "    }\n",
    "\n",
    "    // Store shadow result: 1 for shadow, 0 for no shadow\n",
    "    shadow[idx] = in_shadow;\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Compile the kernel\n",
    "mod = SourceModule(kernel_shadow)\n",
    "calculate_shadows = mod.get_function(\"calculate_shadow\")\n",
    "\n",
    "# Prepare parameters and allocate memory\n",
    "height, width = dsm_img.shape\n",
    "\n",
    "# Allocate memory for input DSM and output shadow map\n",
    "d_dsm = cuda.mem_alloc(dsm_img.nbytes)\n",
    "\n",
    "# Copy DSM to GPU\n",
    "cuda.memcpy_htod(d_dsm, dsm_img)\n",
    "\n",
    "# Initialize shadow output array on CPU\n",
    "shadow_result = np.zeros_like(dsm_img, dtype=bool)\n",
    "\n",
    "# Define block, grid, and cell size\n",
    "block_size = (16, 16, 1)\n",
    "grid_size = (int(np.ceil(width / block_size[0])), int(np.ceil(height / block_size[1])))\n",
    "cell_size = np.float32(pixel_width)\n",
    "\n",
    "# Time and sun parameters\n",
    "time_azi_ele = [\n",
    "      (8, 93.7, 32.87),\n",
    "      (9, 104.85, 44.2),\n",
    "      (10, 119.64, 54.83),\n",
    "      (11, 141.98, 63.58),\n",
    "      (12, 175.62, 67.82),\n",
    "      (13, 211.21, 65.07),\n",
    "      (14, 236, 57.06),\n",
    "      (15, 252.08, 46.7),\n",
    "      (16, 263.83, 35.47),\n",
    "      (17, 273.63, 23.99),\n",
    "      (18, 282.74, 12.65)\n",
    "]\n",
    "\n",
    "# for loop to generate shadow maps for each time and save to tif files\n",
    "for time_val, sun_azimuth, sun_elevation in time_azi_ele:\n",
    "    print(f\"Processing time: {time_val}h, Azimuth: {sun_azimuth}, Elevation: {sun_elevation}\")\n",
    "    \n",
    "    # Allocate memory for the shadow result on the GPU for this iteration.\n",
    "    d_shadow = cuda.mem_alloc(shadow_result.nbytes)\n",
    "    \n",
    "    # Launch the CUDA kernel with the current sun parameters.\n",
    "    calculate_shadows(\n",
    "        d_dsm, d_shadow, np.int32(width), np.int32(height),\n",
    "        np.float32(cell_size), np.float32(sun_azimuth), np.float32(sun_elevation),\n",
    "        block=block_size, grid=grid_size\n",
    "    )\n",
    "    \n",
    "    # Copy the computed shadow data back to the host.\n",
    "    cuda.memcpy_dtoh(shadow_result, d_shadow)\n",
    "    \n",
    "    # Free the shadow memory for this iteration.\n",
    "    d_shadow.free()\n",
    "    \n",
    "    # Prepare an output filename (e.g., \"shadow_8.tif\" for time=8).\n",
    "    output_filename = f\"data/shadow_{time_val}.tif\"\n",
    "    \n",
    "    # For instance, we set the data type to uint8 (1 for shadow, 0 for no shadow)\n",
    "    metadata.update(dtype=rasterio.uint8, count=1)\n",
    "    \n",
    "    # Remove the nodata field from the metadata if it exists, to avoid value range issues\n",
    "    metadata.pop('nodata', None)\n",
    "\n",
    "    # Convert the boolean shadow array to uint8 for saving (1 for True, 0 for False)\n",
    "    shadow_uint8 = shadow_result.astype(np.uint8)\n",
    "    \n",
    "    # Save the shadow distribution as a GeoTIFF file using rasterio.\n",
    "    with rasterio.open(output_filename, 'w', **metadata) as dst:\n",
    "        dst.write(shadow_uint8, 1)\n",
    "    \n",
    "    print(f\"Saved shadow file for time {time_val}h to {output_filename}\")\n",
    "\n",
    "# Free the DSM memory after all iterations are complete.\n",
    "d_dsm.free()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3. Visualize the Result\n",
    "\n",
    "In this section, I will introduce how to visualize the result of the shadow distribution. We can use the `matplotlib` module to plot the shadow distribution for each hour, and save the plot as a png file. Then, we can use the `imageio` module to convert the png files to a gif file, and set the duration of each frame as 1000 ms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PNG file: data/shadow_8.png\n",
      "Saved PNG file: data/shadow_9.png\n",
      "Saved PNG file: data/shadow_10.png\n",
      "Saved PNG file: data/shadow_11.png\n",
      "Saved PNG file: data/shadow_12.png\n",
      "Saved PNG file: data/shadow_13.png\n",
      "Saved PNG file: data/shadow_14.png\n",
      "Saved PNG file: data/shadow_15.png\n",
      "Saved PNG file: data/shadow_16.png\n",
      "Saved PNG file: data/shadow_17.png\n",
      "Saved PNG file: data/shadow_18.png\n",
      "Saved GIF: data/shadow_animation.gif\n"
     ]
    }
   ],
   "source": [
    "import rasterio\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import imageio.v3 as iio\n",
    "\n",
    "# List of times corresponding to shadow files generated earlier\n",
    "times = list(range(8, 19))\n",
    "\n",
    "# Loop through each time value to process each shadow file\n",
    "for time_val in times:\n",
    "    # Construct file paths for the input TIFF and output PNG\n",
    "    tif_path = f\"data/shadow_{time_val}.tif\"\n",
    "    png_path = f\"data/shadow_{time_val}.png\"\n",
    "    \n",
    "    # Open the shadow map using rasterio and read the first band\n",
    "    with rasterio.open(tif_path) as src:\n",
    "        shadow = src.read(1)\n",
    "    \n",
    "    # Create a new figure for visualization\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    \n",
    "    plt.imshow(shadow, cmap='viridis')\n",
    "    plt.title(f\"Shadow Distribution at {time_val}:00\", pad=20, fontsize=18)\n",
    "    plt.axis('off')  # Hide axes\n",
    "\n",
    "    color_no_shadow = \"#440154\"  # for value 0\n",
    "    color_shadow = \"#FDE725\"     # for value 1\n",
    "\n",
    "    # Create custom legend patches using the extracted colors.\n",
    "    shadow_patch = mpatches.Patch(facecolor=color_shadow, label='Shadow (1)')\n",
    "    no_shadow_patch = mpatches.Patch(facecolor=color_no_shadow, label='No Shadow (0)')\n",
    "    \n",
    "    # Add the legend to the plot.\n",
    "    plt.legend(handles=[no_shadow_patch, shadow_patch], loc='lower right', framealpha=0.7)\n",
    "    \n",
    "    # Save the figure to a PNG file and close the figure to free memory\n",
    "    plt.savefig(png_path, bbox_inches='tight', pad_inches=0.2)\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"Saved PNG file: {png_path}\")\n",
    "\n",
    "png_files = [f\"data/shadow_{time_val}.png\" for time_val in times]\n",
    "\n",
    "# Read each image and store them in a list\n",
    "images = []\n",
    "for file in png_files:\n",
    "    images.append(iio.imread(file))\n",
    "\n",
    "# Define the output GIF path\n",
    "gif_path = \"data/shadow_animation.gif\"\n",
    "\n",
    "iio.imwrite(gif_path, images, duration=1000)\n",
    "print(f\"Saved GIF: {gif_path}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [
    {
     "file_id": "1nEIHrJWHBPXn4mP4J8Gf9UB4twWJ_KjX",
     "timestamp": 1741030781669
    },
    {
     "file_id": "1hFVFv5qaKtzUhuFj9MSlp3odBuKTwQoP",
     "timestamp": 1740198055668
    }
   ]
  },
  "kernelspec": {
   "display_name": "spatial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
