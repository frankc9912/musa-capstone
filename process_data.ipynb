{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Data\n",
    "\n",
    "## LiDAR Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pdal\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lidar_dir = \"../data/test\"\n",
    "dsm_dir = \"../data/dsm\"\n",
    "dtm_dir = \"../data/dtm\"\n",
    "ndsm_dir = \"../data/ndsm\"\n",
    "\n",
    "os.makedirs(dsm_dir, exist_ok=True)\n",
    "os.makedirs(dtm_dir, exist_ok=True)\n",
    "os.makedirs(ndsm_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir(lidar_dir):\n",
    "\n",
    "\n",
    "    here i want to add a condition that if the file end with _100.las to _200.las:\n",
    "\n",
    "    \n",
    "    file_path = os.path.join(lidar_dir, file)\n",
    "\n",
    "    output_dsm = os.path.join(dsm_dir, f\"{file.split('.')[0]}_dsm.tif\")\n",
    "    output_dtm = os.path.join(dtm_dir, f\"{file.split('.')[0]}_dtm.tif\")\n",
    "    output_ndsm = os.path.join(ndsm_dir, f\"{file.split('.')[0]}_ndsm.tif\")\n",
    "\n",
    "    # Create a pipeline to read the LAS file and get metadata\n",
    "    pipeline_json = {\n",
    "        \"pipeline\": [\n",
    "            file_path,\n",
    "            {\n",
    "                \"type\": \"filters.info\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    # Run PDAL pipeline\n",
    "    pipeline = pdal.Pipeline(json.dumps(pipeline_json))\n",
    "    pipeline.execute()\n",
    "\n",
    "    # Retrieve metadata\n",
    "    metadata = pipeline.metadata\n",
    "\n",
    "    nav = metadata['metadata']['filters.info']['bbox']\n",
    "\n",
    "    max_x = nav['maxx']\n",
    "    max_y = nav['maxy']\n",
    "    min_x = nav['minx']\n",
    "    min_y = nav['miny']\n",
    "\n",
    "    dtm_pipeline = {\n",
    "        \"pipeline\": [\n",
    "            file_path,\n",
    "            {\n",
    "                \"type\": \"filters.smrf\",  # Simple Morphological Filter to classify ground points\n",
    "                \"ignore\": \"Classification[7:7]\",  # Ignore noise\n",
    "                \"slope\": 0.2,\n",
    "                \"window\": 16,\n",
    "                \"threshold\": 0.5,\n",
    "                \"cell\": 1.0\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"filters.range\",\n",
    "                \"limits\": \"Classification[2:2]\"  # Select only ground points\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"writers.gdal\",\n",
    "                \"filename\": output_dtm,\n",
    "                \"output_type\": \"idw\",  # Inverse Distance Weighting interpolation\n",
    "                \"resolution\": 1.0,\n",
    "                \"bounds\": f\"([{min_x}, {max_x}], [{min_y}, {max_y}])\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    # Initialize the PDAL pipeline with the JSON string.\n",
    "    p_dtm = pdal.Pipeline(json.dumps(dtm_pipeline))\n",
    "    p_dtm.execute()\n",
    "\n",
    "    dsm_pipeline = {\n",
    "        \"pipeline\": [\n",
    "            file_path,\n",
    "            {\n",
    "                \"type\": \"writers.gdal\",\n",
    "                \"filename\": output_dsm,\n",
    "                \"output_type\": \"idw\",\n",
    "                \"resolution\": 1.0,\n",
    "                \"bounds\": f\"([{min_x}, {max_x}], [{min_y}, {max_y}])\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    # Execute the pipeline\n",
    "    p_dsm = pdal.Pipeline(json.dumps(dsm_pipeline))\n",
    "    p_dsm.execute()\n",
    "\n",
    "    # Load the DSM and DTM data\n",
    "    with rasterio.open(output_dsm) as dsm_src, rasterio.open(output_dtm) as dtm_src:\n",
    "        dsm_data = dsm_src.read(1)\n",
    "        dtm_data = dtm_src.read(1)\n",
    "\n",
    "        # Compute nDSM\n",
    "        ndsm_data = dsm_data - dtm_data\n",
    "\n",
    "        # Save the result as a new raster\n",
    "        ndsm_meta = dsm_src.meta.copy()\n",
    "        ndsm_meta.update({\"dtype\": \"float32\"})\n",
    "\n",
    "        with rasterio.open(output_ndsm, \"w\", **ndsm_meta) as dst:\n",
    "            dst.write(ndsm_data.astype(np.float32), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import pdal\n",
    "import rasterio\n",
    "import numpy as np\n",
    "\n",
    "# Loop through each file in the lidar directory.\n",
    "for file in os.listdir(lidar_dir):\n",
    "    # Use a regex to match files ending with _<number>.las\n",
    "    match = re.search(r'_(\\d+)\\.las$', file)\n",
    "    if match:\n",
    "        num = int(match.group(1))\n",
    "        # Process only if the number is between 100 and 200.\n",
    "        if 100 <= num <= 120:\n",
    "            file_path = os.path.join(lidar_dir, file)\n",
    "\n",
    "            output_dsm = os.path.join(dsm_dir, f\"{file.split('.')[0]}_dsm.tif\")\n",
    "            output_dtm = os.path.join(dtm_dir, f\"{file.split('.')[0]}_dtm.tif\")\n",
    "            output_ndsm = os.path.join(ndsm_dir, f\"{file.split('.')[0]}_ndsm.tif\")\n",
    "\n",
    "            # Create a pipeline to read the LAS file and get metadata.\n",
    "            pipeline_json = {\n",
    "                \"pipeline\": [\n",
    "                    file_path,\n",
    "                    {\n",
    "                        \"type\": \"filters.info\"\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "\n",
    "            # Run PDAL pipeline.\n",
    "            pipeline = pdal.Pipeline(json.dumps(pipeline_json))\n",
    "            pipeline.execute()\n",
    "\n",
    "            # Retrieve metadata.\n",
    "            metadata = pipeline.metadata\n",
    "            nav = metadata['metadata']['filters.info']['bbox']\n",
    "\n",
    "            max_x = nav['maxx']\n",
    "            max_y = nav['maxy']\n",
    "            min_x = nav['minx']\n",
    "            min_y = nav['miny']\n",
    "\n",
    "            dtm_pipeline = {\n",
    "                \"pipeline\": [\n",
    "                    file_path,\n",
    "                    {\n",
    "                        \"type\": \"filters.smrf\",  # Simple Morphological Filter to classify ground points.\n",
    "                        \"ignore\": \"Classification[7:7]\",  # Ignore noise.\n",
    "                        \"slope\": 0.2,\n",
    "                        \"window\": 16,\n",
    "                        \"threshold\": 0.5,\n",
    "                        \"cell\": 1.0\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"filters.range\",\n",
    "                        \"limits\": \"Classification[2:2]\"  # Select only ground points.\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"writers.gdal\",\n",
    "                        \"filename\": output_dtm,\n",
    "                        \"output_type\": \"idw\",  # Inverse Distance Weighting interpolation.\n",
    "                        \"resolution\": 1.0,\n",
    "                        \"bounds\": f\"([{min_x}, {max_x}], [{min_y}, {max_y}])\"\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "\n",
    "            # Initialize the PDAL pipeline for DTM.\n",
    "            p_dtm = pdal.Pipeline(json.dumps(dtm_pipeline))\n",
    "            p_dtm.execute()\n",
    "\n",
    "            dsm_pipeline = {\n",
    "                \"pipeline\": [\n",
    "                    file_path,\n",
    "                    {\n",
    "                        \"type\": \"writers.gdal\",\n",
    "                        \"filename\": output_dsm,\n",
    "                        \"output_type\": \"idw\",\n",
    "                        \"resolution\": 1.0,\n",
    "                        \"bounds\": f\"([{min_x}, {max_x}], [{min_y}, {max_y}])\"\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "\n",
    "            # Execute the DSM pipeline.\n",
    "            p_dsm = pdal.Pipeline(json.dumps(dsm_pipeline))\n",
    "            p_dsm.execute()\n",
    "\n",
    "            # Load the DSM and DTM data.\n",
    "            with rasterio.open(output_dsm) as dsm_src, rasterio.open(output_dtm) as dtm_src:\n",
    "                dsm_data = dsm_src.read(1)\n",
    "                dtm_data = dtm_src.read(1)\n",
    "\n",
    "                # Compute nDSM.\n",
    "                ndsm_data = dsm_data - dtm_data\n",
    "\n",
    "                # Save the result as a new raster.\n",
    "                ndsm_meta = dsm_src.meta.copy()\n",
    "                ndsm_meta.update({\"dtype\": \"float32\"})\n",
    "\n",
    "                with rasterio.open(output_ndsm, \"w\", **ndsm_meta) as dst:\n",
    "                    dst.write(ndsm_data.astype(np.float32), 1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai4urban",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
